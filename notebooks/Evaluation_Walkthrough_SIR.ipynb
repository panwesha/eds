{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b''\n",
      "out : b'Already up to date.\\n'\n",
      " Number of regions rows: 412\n",
      " Number of rows: 240\n"
     ]
    }
   ],
   "source": [
    "# %load ../ads_covid-19/src/data/get_data_SIR.py\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                     cwd = os.path.dirname( '../ads_covid-19/data/raw/COVID-19/' ),\n",
    "                     shell = True,\n",
    "                     stdout = subprocess.PIPE,\n",
    "                     stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions / Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('/Users/anweshapanda/ads_covid-19/data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "def get_world_population_data():\n",
    "    page = requests.get(\"https://www.worldometers.info/world-population/population-by-country/\")\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    html_table_pop = soup.find('table')\n",
    "    all_rows_pop = html_table_pop.find_all('tr')\n",
    "    final_pop_data_list=[]\n",
    "    for pos,rows in enumerate(all_rows_pop):\n",
    "        col_list= [each_col.get_text(strip=True) for each_col in rows.find_all('td') ]\n",
    "        final_pop_data_list.append(col_list)\n",
    "    reqd_pop_list = pd.DataFrame(final_pop_data_list).dropna()\\\n",
    "                    .rename(columns={1:'country', 2:'population'})\n",
    "    reqd_pop_list = reqd_pop_list[['country','population']]\n",
    "    reqd_pop_list[\"country\"]= reqd_pop_list[\"country\"].replace({'Myanmar':'Burma', 'Czech Republic (Czechia)': 'Czechia', 'DR Congo': 'Congo (Kinshasa)', 'Congo': 'Congo (Brazzaville)', 'South Korea': 'Korea, South', 'St. Vincent & Grenadines': 'Saint Vincent and the Grenadines', 'Taiwan': 'Taiwan*', 'United States': 'US','State of Palestine': 'West Bank and Gaza', 'CÃ´te d\\'Ivoire': 'Cote d\\'Ivoire'})\n",
    "    list_new_country = [pd.Series(['Diamond Princess', 3711], index = reqd_pop_list.columns ) ,\n",
    "                    pd.Series(['Kosovo', 1845000], index = reqd_pop_list.columns ) ,\n",
    "                    pd.Series(['MS Zaandam', 1432], index = reqd_pop_list.columns ),\n",
    "                    pd.Series(['Saint Kitts and Nevis', 52441], index = reqd_pop_list.columns ),\n",
    "                    pd.Series(['Sao Tome and Principe', 211028], index = reqd_pop_list.columns )]\n",
    "\n",
    "    reqd_pop_list = reqd_pop_list.append(list_new_country, ignore_index=True)\\\n",
    "                                .sort_values('country')\\\n",
    "                                .reset_index(drop=True)\n",
    "    reqd_pop_list.to_csv('../ads_covid-19/data/raw/population_data.csv',sep=';',index=False)\n",
    "    print(' Number of rows: '+str(reqd_pop_list.shape[0]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    get_current_data_germany()\n",
    "    get_world_population_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 63042\n",
      " Number of rows stored in countries: 237\n"
     ]
    }
   ],
   "source": [
    "# %load ../ads_covid-19/src/data/process_JH_data_SIR.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "    data_path='/Users/anweshapanda/ads_covid-19/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                  'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                            .T                              \\\n",
    "                            .stack(level=[0,1])             \\\n",
    "                            .reset_index()                  \\\n",
    "                            .rename(columns={'level_0':'date',\n",
    "                                               0:'confirmed'},\n",
    "                                              )\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    pd_relational_model.to_csv('/Users/anweshapanda/ads_covid-19/data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "\n",
    "def data_preparation_of_countries():\n",
    "    COVID_data_path='/Users/anweshapanda/ads_covid-19/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    df_data = pd.read_csv(COVID_data_path)\n",
    "    df_data = df_data.drop(['Lat','Long'],axis=1)\n",
    "    df_data = df_data.rename(columns={'Country/Region':'country',\n",
    "                                   'Province/State':'state'})\n",
    "    df_data['state'] = df_data['state'].fillna('no')\n",
    "    full_country_list = df_data['country'].unique().tolist()\n",
    "    time_idx = df_data.columns[2:]\n",
    "    df_analyse = pd.DataFrame({\n",
    "    'date':time_idx})\n",
    "    for each in full_country_list:\n",
    "        df_analyse[each] = np.array(df_data[df_data['country']==each].iloc[:,2::].sum(axis=0))\n",
    "    time_idx=[datetime.strptime(each,\"%m/%d/%y\") for each in df_analyse.date] # convert to datetime\n",
    "    time_str=[each.strftime('%y-%m-%d') for each in time_idx] # convert back to date ISO norm (str)\n",
    "    df_analyse['date']=time_idx\n",
    "    df_analyse.to_csv('/Users/anweshapanda/ads_covid-19/data/processed/all_country_flat_table.csv', sep=';',index=False)\n",
    "    print(' Number of rows stored in countries: '+str(df_analyse.shape[0]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n",
    "    data_preparation_of_countries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/EnterpriseDataScience/lib/python3.7/site-packages/scipy/optimize/minpack.py:829: OptimizeWarning:\n",
      "\n",
      "Covariance of the parameters could not be estimated\n",
      "\n",
      "/opt/anaconda3/envs/EnterpriseDataScience/lib/python3.7/site-packages/ipykernel_launcher.py:111: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "/opt/anaconda3/envs/EnterpriseDataScience/lib/python3.7/site-packages/ipykernel_launcher.py:112: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "/opt/anaconda3/envs/EnterpriseDataScience/lib/python3.7/site-packages/scipy/integrate/odepack.py:247: ODEintWarning:\n",
      "\n",
      "Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows stored in optimized df:4\n",
      "Number of rows stored in fitted_SIR_data:162\n"
     ]
    }
   ],
   "source": [
    "# %load ../ads_covid-19/src/features/build_feature_SIR.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 9)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "def data_gathering():\n",
    "    population_df = pd.read_csv('/Users/anweshapanda/ads_covid-19/data/raw/population_data.csv',sep=';', thousands=',')\n",
    "    population_df = population_df.set_index(['country']).T\n",
    "    df_analyse=pd.read_csv('/Users/anweshapanda/ads_covid-19/data/processed/all_country_flat_table.csv',sep=';')\n",
    "    country_list = df_analyse.columns[1:]\n",
    "\n",
    "    data_y = []\n",
    "    t=[]\n",
    "    for column in df_analyse.columns:\n",
    "         data_y.append(np.array(df_analyse[column][75:]))\n",
    "\n",
    "    t = np.arange(len(data_y))\n",
    "    data_y_df = pd.DataFrame(data_y,index=df_analyse.columns).T\n",
    "    data_y_df.to_csv('/Users/anweshapanda/ads_covid-19/data/processed/sir/ydata_SIR_data.csv',sep=';',index=False)\n",
    "    optimized_df = pd.DataFrame(columns = df_analyse.columns[1:],\n",
    "                     index = ['opt_beta', 'opt_gamma', 'std_dev_error_beta', 'std_dev_error_gamma'])\n",
    "\n",
    "    t = []\n",
    "    fitted_final_data = []\n",
    "\n",
    "    global I0, N0, S0, R0\n",
    "    for column in data_y_df.columns[1:]:\n",
    "        I0 = data_y_df[column].loc[0]\n",
    "        N0 = population_df[column].loc['population']\n",
    "        S0 = N0-I0\n",
    "        R0 = 0\n",
    "        t  = np.arange(len(data_y_df[column]))\n",
    "\n",
    "        popt=[0.4,0.1]\n",
    "\n",
    "        fit_odeint(t, *popt)\n",
    "\n",
    "\n",
    "        popt, pcov = optimize.curve_fit(fit_odeint, t, data_y_df[column], maxfev=5000)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "\n",
    "        optimized_df.at['opt_beta', column] = popt[0]\n",
    "        optimized_df.at['opt_gamma', column] = popt[1]\n",
    "        optimized_df.at['std_dev_error_beta', column] = perr[0]\n",
    "        optimized_df.at['std_dev_error_gamma', column] = perr[1]\n",
    "\n",
    "        fitted = fit_odeint(t, *popt)\n",
    "        fitted_final_data.append(np.array(fitted))\n",
    "\n",
    "    optimized_df.to_csv('/Users/anweshapanda/ads_covid-19/data/processed/sir/optimized_SIR_data.csv',sep=';',index=False)\n",
    "    fitted_SIR_data_df = pd.DataFrame(fitted_final_data,index=df_analyse.columns[1:]).T\n",
    "    fitted_SIR_data_df.to_csv('/Users/anweshapanda/ads_covid-19/data/processed/sir/fitted_SIR_data.csv',sep=';',index=False)\n",
    "    print('Number of rows stored in optimized df:' +str(optimized_df.shape[0]))\n",
    "    print('Number of rows stored in fitted_SIR_data:' +str(fitted_SIR_data_df.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit_odeint(t, beta, gamma):\n",
    "\n",
    "    '''\n",
    "    helper function for the integration\n",
    "    '''\n",
    "    return integrate.odeint(SIR_model_t, (S0, I0, R0, N0), t, args=(beta, gamma))[:,1]\n",
    "\n",
    "\n",
    "def SIR_model_t(SIRN,t,beta,gamma):\n",
    "    ''' Simple SIR model\n",
    "    S: susceptible population\n",
    "    t: time step, mandatory for integral.odeint\n",
    "    I: infected people\n",
    "    R: recovered people\n",
    "    beta:\n",
    "\n",
    "    overall condition is that the sum of changes (differnces) sum up to 0\n",
    "    dS+dI+dR=0\n",
    "    S+I+R= N (constant size of population)\n",
    "\n",
    "    '''\n",
    "\n",
    "    S,I,R,N=SIRN\n",
    "    dS_dt=-beta*S*I/N          #S*I is the\n",
    "    dI_dt=beta*S*I/N-gamma*I\n",
    "    dR_dt=gamma*I\n",
    "    dN_dt=0\n",
    "    return dS_dt,dI_dt,dR_dt,dN_dt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_gathering()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anweshapanda/Enterprise Data Science\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load ../ads_covid-19/src/visualization/visualize_SIR.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "fitted_final_data_dash_df = pd.read_csv('/Users/anweshapanda/ads_covid-19/data/processed/sir/fitted_SIR_data.csv',sep=';')\n",
    "yd = fitted_final_data_dash_df.copy()\n",
    "# Initial reading of required data\n",
    "#df_input_large=pd.read_csv('../ads_covid-19/data/processed/COVID_final_set.csv',sep=';')\n",
    "fitted_final_data_dash_df = pd.read_csv('/Users/anweshapanda/ads_covid-19/data/processed/SIR/fitted_SIR_data.csv',sep=';')\n",
    "optimized_dash_df = pd.read_csv('/Users/anweshapanda/ads_covid-19/data/processed/SIR/optimized_SIR_data.csv',sep=';')\n",
    "ydata_dash_df = pd.read_csv('/Users/anweshapanda/ads_covid-19/data/processed/SIR/ydata_SIR_data.csv',sep=';')\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "    Goal of the project is to learn data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in fitted_final_data_dash_df],\n",
    "        value=['US', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select SIR Model and/or fitted SIR Model\n",
    "        '''),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'SIR curve and fitted SIR curve ', 'value': 'SIR_value'},\n",
    "\n",
    "    ],\n",
    "    value='SIR_value',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(full_country_list,show_doubling):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in full_country_list:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        traces.append(dict(x=ydata_dash_df.date, #df_plot.date,\n",
    "                                y=ydata_dash_df[each], #=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                line_width=2,\n",
    "                                marker_size=4,\n",
    "                                name=each\n",
    "\n",
    "                        )\n",
    "                )\n",
    "        traces.append(dict(x=ydata_dash_df.date, #df_plot.date,\n",
    "                                y=fitted_final_data_dash_df[each], #=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                line_width=2,\n",
    "                                marker_size=4,\n",
    "                                name=each+'_fitted'\n",
    "\n",
    "                        )\n",
    "                )\n",
    "\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis={'type': 'log',\n",
    "                        'range': '[1.1,5.5]',\n",
    "                        'title':'Number of people infected'\n",
    "                        }\n",
    "\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, host='127.0.0.1', port = 8051, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
